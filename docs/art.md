
# StreamForge: лаборатория данных и агентных решений от single-host к multi-cluster

*(и почему я отказался от FastAPI-first в пользу Kafka-first)*

---

## Введение

StreamForge начинался как моя личная лаборатория: набор Python-скриптов и Jupyter-ноутбуков, где я проверял идеи в трейдинге и анализе графовых данных.
Но со временем стало очевидно: если я хочу построить **систему для реального мира**, этого мало. Нужно было перейти от single-host экспериментов к **multi-cluster, event-driven платформе**, где микросервисы обмениваются данными через Kafka, а модели машинного обучения разворачиваются в продакшене.

StreamForge стал именно такой системой. Сегодня это **архитектура микросервисов**, работающих в Kubernetes, управляемых через Terraform и ArgoCD, с CI/CD в GitLab.
В основе — **Kafka-first подход**: события становятся «языком общения» между сервисами, а API лишь точка входа.

---

## Архитектура и компоненты

Ключевая идея StreamForge — **событийная шина (Kafka)** как единый слой интеграции.

* **Queue Manager** (FastAPI)
  Принимает команды через REST (например, `POST /queues/start`). Создаёт Kubernetes Job и публикует событие в Kafka (topic `queue-control`).

* **Loader Producer**
  Job, который получает исторические данные (например, свечи Binance), обогащает их и отправляет в Kafka (topic `btc-5m`).

* **Arango Connector**
  Consumer, который пишет данные из Kafka в ArangoDB. Здесь же считаются индикаторы (RSI, VWAP, волатильность).

* **Visualizer**
  Consumer, подключённый к тому же Kafka topic, но со своей consumer group. Отображает данные в виде свечных графиков и тепловых карт.

* **RL Agent (PPO)**
  Consumer, который получает поток котировок и принимает торговые решения. Использует PPO (Proximal Policy Optimization), обученный на исторических данных, и проверяет стратегию в реальном времени.

* **GNN Trainer**
  Batch-job для построения графа связей между токенами/акциями и обучения моделей PyG/DGL. Результаты тоже пишутся в Kafka и ArangoDB.

* **State Store (ArangoDB)**
  Хранит состояние очередей, мета-информацию о Job и enriched-данные.

* **Model Store (MinIO / GCP S3)**
  Все веса моделей (PPO, GNN) сохраняются сюда. Consumer-сервисы могут получать новые версии моделей через Kafka-события.

---

## От FastAPI-first к Kafka-first

В первых версиях системы я строил всё вокруг FastAPI: сервисы дергали друг друга через REST.
Это было удобно, но слишком жёстко связывало компоненты.

Теперь же всё иначе:

1. **API остаётся только точкой входа.**
   Queue Manager принимает команду, но дальше всё уходит в Kafka.

2. **События буферизуются.**
   Если consumer временно недоступен — сообщения сохраняются, а данные не теряются.

3. **Слабое связывание.**
   Loader может писать свечи, а одновременно несколько consumer groups (Arango, Visualizer, RL Agent) читают один и тот же поток, но обрабатывают его независимо.

4. **Масштабирование.**
   Добавляю ещё один consumer-pod — и Kafka сама перераспределяет партиции.

---

## Consumer groups и offsets

Kafka даёт возможность для каждого микросервиса работать в **своей consumer group**.

Пример:

* `arango-connector-group` пишет все данные в БД;
* `visualizer-group` работает в реальном времени, может отставать на секунды;
* `rl-agent-group` использует данные с минимальной задержкой для инференса.

У каждого — **свой offset**. Это значит, что даже если визуализатор тормозит, агент не задерживается.
А если я запускаю ещё 3 экземпляра RL Agent — Kafka автоматически делит нагрузку.

---

## RL агент (PPO DRL) в системе

Одним из ключевых сервисов StreamForge стал **агент на основе обучения с подкреплением (RL)**.

Я выбрал **PPO (Proximal Policy Optimization)**, так как этот алгоритм хорошо работает в стохастических и нестационарных средах, где рынок постоянно меняется.

Архитектура агента:

* **Среда (TradingEnv)**
  Состояние = баланс + позиции + окно исторических цен и индикаторов (RSI, скользящие средние, волатильность).
  Действия = купить, продать, удерживать.
  Награда = изменение стоимости портфеля (с учётом комиссий).

* **Агент (PPO)**
  Политика = нейросеть на TensorFlow (с LSTM).
  Функция ценности = отдельная нейросеть.
  Логирование = PostgreSQL (через `postgres_logger`).

* **Инференс**
  Агент работает как consumer Kafka: читает поток свечей, принимает решение, пишет результат в другой topic.

* **Хранилище моделей**
  Все checkpoint’ы сохраняются в MinIO. Новая версия модели рассылается через Kafka-событие, и consumer-сервисы получают обновление «на лету».

---

## Анализ рисков и бэктестинг

Финансовый рынок — это не только ROI, но и риск. Поэтому в StreamForge я интегрировал методы оценки:

* **Sharpe Ratio** — доходность, скорректированная на риск.
* **Sortino Ratio** — то же, но учитывает только негативную волатильность.
* **Volatility Analysis** — оценка колебаний на разных таймфреймах.
* **Transaction Costs** — комиссии и проскальзывания.

Для проверки стратегий использую **backtesting с walk-forward validation**:
агент обучается на одном промежутке, затем проверяется на следующем, чтобы избежать переобучения.

---

## DevOps и инфраструктура

StreamForge развернут в **GKE (Google Kubernetes Engine)** и управляется через Terraform.
Основные решения:

* **GitLab CI/CD + ArgoCD** — полный GitOps.
* **KEDA** — автоскейлинг consumer-сервисов по нагрузке на Kafka.
* **Vault CSI** — безопасное хранение секретов.
* **Nvidia GPU Operator** — для тренировки RL и GNN в кластере.
* **Observability** — Prometheus + Grafana + EFK (Elasticsearch + Fluent Bit + Kibana).

---

## Бизнес-логика и личная история

Когда я начинал, всё выглядело как простой эксперимент: «а что если мой PPO-агент сможет обыграть рынок?».
Но со временем стало ясно: ценность не только в агенте, а в **системе вокруг него**.

StreamForge превратился в **лабораторию данных**, где:

* данные собираются и обогащаются;
* модели обучаются и валидируются;
* решения агентов тестируются и сравниваются;
* вся система масштабируется от одного ноутбука до облачного кластера.

Сегодня я смотрю на StreamForge не как на трейдинг-бота, а как на **универсальную платформу для event-driven ML**.

---

## Заключение и планы

StreamForge стал для меня мостом от single-host экспериментов к multi-cluster продакшену.

В будущем я хочу добавить:

* **multi-agent RL** (несколько агентов с разными стратегиями);
* **онлайн-обновление моделей через Kafka**;
* **поддержку гибридных сценариев (RL + GNN)**;
* **открытый API для внешних consumer-сервисов вне Kubernetes-кластера**.

---

##  Приложение: Таблица технологий StreamForge (расширенная)

| Слой / Компонент             | Технологии и библиотеки                                                                                               | Назначение                                                                                          |
| ---------------------------- | --------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------- |
| **Ingestion (сбор)**         | **FastAPI**, **httpx**, **asyncio**, **aiokafka**, **Binance REST/WebSocket API**                                     | Loader Producer: получение сырых данных (свечи, трейды), публикация в Kafka                         |
| **Enrichment (обогащение)**  | **python-arango**, **pandas**, **ta-lib**, **numpy**, **aiokafka**                                                    | Arango Connector: запись данных в ArangoDB, расчёт RSI/VWAP/Volatility, публикация enriched-потоков |
| **Aggregation (агрегация)**  | **ArangoDB (AQL, Graph API)**, **networkx**, **cugraph** (экспериментально для GPU)                                   | Хранение агрегированных данных, построение графов, аналитические запросы                            |
| **Analytics / ML inference** | **TensorFlow (PPO DRL агент)**, **PyTorch**, **PyTorch Geometric (PyG)**, **DGL**, **JupyterLab**, **MinIO (S3 API)** | Обучение PPO/GNN моделей, инференс в реальном времени, хранение моделей                             |
| **Event-driven core**        | **Apache Kafka**, **aiokafka**, **confluent-kafka-python**, Consumer Groups                                           | Событийная шина, независимая обработка потоков разными сервисами                                    |
| **State Store**              | **ArangoDB**, **SQLAlchemy**, **PostgreSQL**, **asyncpg**                                                             | Хранение состояния очередей, логирование ROI, backtesting-результатов                               |
| **Observability**            | **Prometheus client (prometheus-fastapi-instrumentator)**, **Grafana**, **EFK (Elasticsearch + Fluent Bit + Kibana)** | Мониторинг сервисов, логирование, алертинг                                                          |
| **Orchestration**            | **Kubernetes (GKE)**, **Helm**, **Terraform**, **ArgoCD**, **KEDA**                                                   | Автоматический деплой, GitOps, автоскейлинг consumers                                               |
| **Security**                 | **HashiCorp Vault CSI driver**, **cert-manager**, **Kafka TLS/SCRAM-SHA-512**, **Keycloak (OIDC/OAuth2)**             | Управление секретами, безопасные подключения, аутентификация                                        |
| **Compute / AI infra**       | **NVIDIA GPU Operator**, **CUDA/cuDNN**, **TensorFlow-GPU**, **PyTorch Lightning**                                    | GPU-ускорение обучения и инференса                                                                  |
| **API/UI**                   | **FastAPI**, **Jinja2**, **Starlette WebSockets**, **uvicorn**, **Bootstrap/Chart.js/D3.js**                          | REST API, веб-интерфейс, визуализация свечных графиков и индикаторов                                |

---
